{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch_geometric.nn as geonn\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gfos.data.utils import load_layout\n",
    "from gfos.data.dataset import LayoutDataset, Normalizer\n",
    "from gfos.metrics import kendall, topk_error\n",
    "from gfos.loss import MultiElementRankLoss\n",
    "from gfos.utils.misc import seed_everything\n",
    "from gfos.data.constants import mask_min_max\n",
    "\n",
    "SEED = 42\n",
    "DEBUG = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"layout_gnn_gnn_3.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYOUT_DIR = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\"\n",
    "\n",
    "configs = dict(\n",
    "    conv_layer=\"SAGEConv\",\n",
    "    num_layers=4,\n",
    "    op_embedding_dim=32,\n",
    "    config_dim=64,\n",
    "    graph_dim=64,\n",
    "    num_epochs=2000,\n",
    "    learning_rate=2e-3,\n",
    "    weight_decay=1e-6,\n",
    "    min_lr=1e-7,\n",
    "    max_configs=10240,\n",
    "    num_configs=256,\n",
    "    loss_margin=0.5,\n",
    "    loss_num_permutations=100,\n",
    "    accum_iter=4,\n",
    "    grad_clip=1e-2,\n",
    ")\n",
    "\n",
    "SOURCE = \"xla\"\n",
    "SEARCH = \"random\"\n",
    "WANDB_PROJECT = \"gfos\"\n",
    "WANDB_DIR = \"../../logs/\"\n",
    "WANDB_RUN_NAME = f\"layout_{SOURCE}_{SEARCH}\"\n",
    "TAGS = [\"train\", \"layout\", SOURCE, SEARCH]\n",
    "\n",
    "NUM_VAL_EPOCHS = 40\n",
    "INFERENCE_CONFIGS_BATCH_SIZE = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_neighbors(node_feat: torch.Tensor, edge_index: torch.Tensor):\n",
    "    source_nodes = edge_index[0]\n",
    "    target_nodes = edge_index[1]\n",
    "\n",
    "    in_degree_features = torch.zeros_like(node_feat, device=node_feat.device)\n",
    "    out_degree_features = torch.zeros_like(node_feat, device=node_feat.device)\n",
    "\n",
    "    source_node_features = node_feat[source_nodes]\n",
    "    target_node_features = node_feat[target_nodes]\n",
    "\n",
    "    in_degree_features.scatter_reduce_(\n",
    "        0,\n",
    "        target_nodes.unsqueeze(-1).expand_as(source_node_features),\n",
    "        source_node_features,\n",
    "        reduce=\"mean\",\n",
    "        include_self=False,\n",
    "    )\n",
    "\n",
    "    out_degree_features.scatter_reduce_(\n",
    "        0,\n",
    "        source_nodes.unsqueeze(-1).expand_as(target_node_features),\n",
    "        target_node_features,\n",
    "        reduce=\"mean\",\n",
    "        include_self=False,\n",
    "    )\n",
    "\n",
    "    return out_degree_features - in_degree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        op_embedding_dim: int = 32,\n",
    "        config_dim: int = 64,\n",
    "        graph_dim: int = 64,\n",
    "        num_layers: int = 3,\n",
    "        node_feat_dim: int = 140,\n",
    "        node_config_dim: int = 18,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        NUM_OPCODE = 120\n",
    "        merged_node_dim = graph_dim + config_dim\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            NUM_OPCODE,\n",
    "            op_embedding_dim,\n",
    "        )\n",
    "        in_channels = op_embedding_dim + node_feat_dim\n",
    "\n",
    "        self.model_gnn = geonn.models.GraphSAGE(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=graph_dim,\n",
    "            num_layers=num_layers*2,\n",
    "            out_channels=graph_dim,\n",
    "            act=\"leaky_relu\",\n",
    "            norm=\"batch\",\n",
    "        )\n",
    "\n",
    "        self.config_mp = geonn.models.GAT(\n",
    "            in_channels=graph_dim,\n",
    "            hidden_channels=graph_dim,\n",
    "            num_layers=3,\n",
    "            act=\"leaky_relu\",\n",
    "            norm=\"batch\", \n",
    "        )\n",
    "\n",
    "        self.config_gnn = geonn.models.GraphSAGE(\n",
    "            in_channels=merged_node_dim,\n",
    "            hidden_channels=config_dim,\n",
    "            num_layers=num_layers,\n",
    "            out_channels=config_dim,\n",
    "            act=\"leaky_relu\",\n",
    "            norm=\"batch\",\n",
    "            js=\"max\",\n",
    "        )\n",
    "\n",
    "        self.config_prj = nn.Sequential(\n",
    "            nn.Linear(node_config_dim, config_dim),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(config_dim, 64, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feat: torch.Tensor,\n",
    "        node_opcode: torch.Tensor,\n",
    "        edge_index: torch.Tensor,\n",
    "        node_config_feat: torch.Tensor,\n",
    "        node_config_ids: torch.Tensor,\n",
    "        config_edge_index: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # Get graph features\n",
    "        c = node_config_feat.size(0)\n",
    "\n",
    "        x = torch.cat([node_feat, self.embedding(node_opcode)], dim=1)\n",
    "\n",
    "        # Get graph features\n",
    "        x = self.model_gnn(x, edge_index)\n",
    "\n",
    "        config_neighbors = aggregate_neighbors(x, edge_index)[node_config_ids]\n",
    "        config_neighbors = nn.functional.normalize(config_neighbors, dim=-1)\n",
    "        config_neighbors = self.config_mp(config_neighbors, config_edge_index)\n",
    "\n",
    "        # (N, graph_out) -> (NC, graph_out)\n",
    "        x = x[node_config_ids]\n",
    "        # x += neighbor_feat\n",
    "\n",
    "        # Merge graph features with config features\n",
    "        # (C, NC, 18) -> (C, NC, config_dim)\n",
    "        node_config_feat = self.config_prj(node_config_feat)\n",
    "        # pos_embedding = self.deg_prj(neighbor_feat)\n",
    "\n",
    "        # (C, NC, 2*graph_out + config_dim)\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                config_neighbors.repeat((c, 1, 1)),\n",
    "                x.repeat((c, 1, 1)),\n",
    "                node_config_feat,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # x += pos_embedding\n",
    "        x = nn.functional.normalize(x, dim=-1)\n",
    "\n",
    "        datas = [\n",
    "            Data(x=x[i], edge_index=config_edge_index)\n",
    "            for i in range(x.shape[0])\n",
    "        ]\n",
    "        batch = Batch.from_data_list(datas)\n",
    "\n",
    "        x = self.config_gnn(batch.x, batch.edge_index)\n",
    "        x = geonn.pool.global_mean_pool(x, batch.batch)\n",
    "\n",
    "        x = self.dense(x).flatten()\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = configs[\"conv_layer\"]\n",
    "num_layers = configs[\"num_layers\"]\n",
    "op_embedding_dim = configs[\"op_embedding_dim\"]\n",
    "config_dim = configs[\"config_dim\"]\n",
    "graph_dim = configs[\"graph_dim\"]\n",
    "num_epochs = configs[\"num_epochs\"]\n",
    "learning_rate = configs[\"learning_rate\"]\n",
    "weight_decay = configs[\"weight_decay\"]\n",
    "min_lr = configs[\"min_lr\"]\n",
    "max_configs = configs[\"max_configs\"]\n",
    "c = configs[\"num_configs\"]\n",
    "accum_iter = configs[\"accum_iter\"]\n",
    "grad_clip = configs[\"grad_clip\"]\n",
    "margin = configs[\"loss_margin\"]\n",
    "number_permutations = configs[\"loss_num_permutations\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 69/69 [00:35<00:00,  1.97it/s]\n",
      "Loading data: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer.from_configs(mask_min_max, SOURCE, SEARCH)\n",
    "\n",
    "layout_data = load_layout(\n",
    "    LAYOUT_DIR,\n",
    "    model_type=SOURCE,\n",
    "    compile_type=SEARCH,\n",
    ")\n",
    "\n",
    "train_dataset = LayoutDataset(\n",
    "    layout_data[\"train\"],\n",
    "    max_configs=max_configs,\n",
    "    num_configs=c,\n",
    "    config_edges=\"simple\",\n",
    "    normalizer=normalizer,\n",
    ")\n",
    "val_dataset = LayoutDataset(\n",
    "    layout_data[\"valid\"], config_edges=\"simple\", normalizer=normalizer\n",
    ")\n",
    "\n",
    "\n",
    "# pickle.dump(train_dataset, open(\"../../data/train_dataset.pkl\", \"wb\"))\n",
    "# pickle.dump(val_dataset, open(\"../../data/val_dataset.pkl\", \"wb\"))\n",
    "\n",
    "# train_dataset = pickle.load(open(\"../../data/train_dataset.pkl\", \"rb\"))\n",
    "# val_dataset = pickle.load(open(\"../../data/val_dataset.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_dim = train_dataset[0][\"node_feat\"].shape[-1]\n",
    "node_config_dim = train_dataset[0][\"node_config_feat\"].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, loss, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayoutModel(\n",
    "    op_embedding_dim=op_embedding_dim,\n",
    "    config_dim=config_dim,\n",
    "    graph_dim=graph_dim,\n",
    "    node_feat_dim=node_feat_dim,\n",
    "    node_config_dim=node_config_dim,\n",
    "    num_layers=num_layers,\n",
    ").to(device)\n",
    "\n",
    "criterion = MultiElementRankLoss(\n",
    "    margin=margin, number_permutations=number_permutations\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {\"name\": \"lr_embed\", 'params': model.embedding.parameters(), 'lr': learning_rate / 10},\n",
    "    {\"name\": \"lr_model_gnn\", 'params': model.model_gnn.parameters(), 'lr': learning_rate / 10},\n",
    "    {\"name\": \"lr_config_prj\", 'params': model.config_prj.parameters(), 'lr': learning_rate / 10},\n",
    "    {\"name\": \"lr_config_mp\", 'params': model.config_mp.parameters(), 'lr': learning_rate / 10},\n",
    "    {\"name\": \"lr_config_gnn\", 'params': model.config_gnn.parameters(), 'lr': learning_rate},\n",
    "    {\"name\": \"lr_dense\", 'params': model.dense.parameters(), 'lr': learning_rate},\n",
    "], betas=[0.85, 0.9], weight_decay=weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.1,\n",
    "    patience=5, # 5 times evaluation = 5 * NUM_VAL_EPOCHS epochs\n",
    "    threshold=0.01,\n",
    "    min_lr=min_lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Don't know why but this cost huge amount of VRAM\n",
    "opa = tfr.keras.metrics.OPAMetric()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init wandb and train&valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33medenn0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../logs/wandb\\run-20231004_012417-0yhv1szs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/edenn0/gfos/runs/0yhv1szs' target=\"_blank\">layout_xla_random</a></strong> to <a href='https://wandb.ai/edenn0/gfos' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/edenn0/gfos' target=\"_blank\">https://wandb.ai/edenn0/gfos</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/edenn0/gfos/runs/0yhv1szs' target=\"_blank\">https://wandb.ai/edenn0/gfos/runs/0yhv1szs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    run = wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        dir=WANDB_DIR,\n",
    "        name=WANDB_RUN_NAME,\n",
    "        config=configs,\n",
    "        tags=TAGS,\n",
    "    )\n",
    "    run.watch(model, log=\"all\")\n",
    "    run.log_code(\"../\")\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_dir = f\"../../logs/{WANDB_RUN_NAME}/{time_str}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(precision=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, kendall = 0.0506,opa = 0.6990, top500 = 0.8134\n",
      "Best score updated: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, kendall = 0.0668,opa = 0.6690, top500 = 0.7960\n",
      "Best score updated: 0.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119, kendall = 0.0793,opa = 0.6679, top500 = 0.7186\n",
      "Best score updated: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159, kendall = 0.0805,opa = 0.6939, top500 = 0.7380\n",
      "Best score updated: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199, kendall = 0.0833,opa = 0.6892, top500 = 0.7811\n",
      "Best score updated: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 239, kendall = 0.1481,opa = 0.7070, top500 = 0.6997\n",
      "Best score updated: 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 279, kendall = 0.1360,opa = 0.7205, top500 = 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 319, kendall = 0.1813,opa = 0.7321, top500 = 0.6714\n",
      "Best score updated: 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 359, kendall = 0.1733,opa = 0.7404, top500 = 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 399, kendall = 0.1858,opa = 0.7485, top500 = 0.6040\n",
      "Best score updated: 0.1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 439, kendall = 0.1591,opa = 0.7531, top500 = 0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 479, kendall = 0.2001,opa = 0.7592, top500 = 0.6046\n",
      "Best score updated: 0.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 519, kendall = 0.1597,opa = 0.7641, top500 = 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 559, kendall = 0.1631,opa = 0.7685, top500 = 0.6634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 599, kendall = 0.1479,opa = 0.7711, top500 = 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 639, kendall = 0.1597,opa = 0.7734, top500 = 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 679, kendall = 0.1394,opa = 0.7746, top500 = 0.6706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 719, kendall = 0.1700,opa = 0.7762, top500 = 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 759, kendall = 0.1714,opa = 0.7784, top500 = 0.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 799, kendall = 0.1591,opa = 0.7802, top500 = 0.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 839, kendall = 0.1754,opa = 0.7816, top500 = 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 879, kendall = 0.1684,opa = 0.7829, top500 = 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 919, kendall = 0.1527,opa = 0.7843, top500 = 0.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 959, kendall = 0.1303,opa = 0.7843, top500 = 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 999, kendall = 0.1783,opa = 0.7848, top500 = 0.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1039, kendall = 0.1749,opa = 0.7863, top500 = 0.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1079, kendall = 0.1481,opa = 0.7870, top500 = 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1119, kendall = 0.1525,opa = 0.7869, top500 = 0.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1159, kendall = 0.1399,opa = 0.7866, top500 = 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1169 loss: 0.08:  61%|██████    | 42/69 [00:15<00:08,  3.23it/s]"
     ]
    }
   ],
   "source": [
    "best_score = -1\n",
    "loss_mean = 0\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training dataset\n",
    "    permutation = np.random.permutation(len(train_dataset))\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    pbar = tqdm(permutation, leave=False)\n",
    "\n",
    "    for i in pbar:\n",
    "        record = train_dataset[i]\n",
    "        node_feat = record[\"node_feat\"]\n",
    "        node_opcode = record[\"node_opcode\"]\n",
    "        edge_index = record[\"edge_index\"]\n",
    "        node_config_feat = record[\"node_config_feat\"]\n",
    "        node_config_ids = record[\"node_config_ids\"]\n",
    "        config_runtime = record[\"config_runtime\"]\n",
    "        config_edge_index = record[\"config_edge_index\"]\n",
    "\n",
    "        (\n",
    "            node_feat,\n",
    "            node_opcode,\n",
    "            edge_index,\n",
    "            node_config_feat,\n",
    "            node_config_ids,\n",
    "            config_runtime,\n",
    "            config_edge_index,\n",
    "        ) = (\n",
    "            node_feat.to(device),\n",
    "            node_opcode.to(device),\n",
    "            edge_index.to(device),\n",
    "            node_config_feat.to(device),\n",
    "            node_config_ids.to(device),\n",
    "            config_runtime.to(device),\n",
    "            config_edge_index.to(device),\n",
    "        )\n",
    "\n",
    "        with autocast():\n",
    "            out = model(\n",
    "                node_feat,\n",
    "                node_opcode,\n",
    "                edge_index,\n",
    "                node_config_feat,\n",
    "                node_config_ids,\n",
    "                config_edge_index,\n",
    "            )\n",
    "\n",
    "            loss = criterion(out, config_runtime)\n",
    "            loss = loss / accum_iter\n",
    "            loss_mean += loss.item()\n",
    "        # loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "        pbar.set_description(f\"epoch: {epoch} loss: {loss_mean:.4f}\")\n",
    "        \n",
    "        if ((i + 1) % accum_iter == 0) or (i + 1 == len(train_dataset)):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            # optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if not DEBUG:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"train/lr_slow\": optimizer.param_groups[0][\"lr\"],\n",
    "                        \"train/lr_fast\": optimizer.param_groups[-1][\"lr\"],\n",
    "                        \"train/loss\": loss_mean,\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            loss_mean = 0\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if (epoch + 1) % NUM_VAL_EPOCHS != 0 and epoch != num_epochs - 1:\n",
    "        continue\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Validation phase\n",
    "    # Scores placeholder\n",
    "    val_loss = []\n",
    "    kendalltau_scores = []\n",
    "    opa_scores = []\n",
    "    top500_scores = []\n",
    "    top100_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for record in tqdm(val_dataset, desc=\"valid\", leave=False):\n",
    "            node_feat = record[\"node_feat\"]\n",
    "            node_opcode = record[\"node_opcode\"]\n",
    "            edge_index = record[\"edge_index\"]\n",
    "            node_config_feat = record[\"node_config_feat\"]\n",
    "            node_config_ids = record[\"node_config_ids\"]\n",
    "            config_runtime = record[\"config_runtime\"]\n",
    "            config_edge_index = record[\"config_edge_index\"]\n",
    "\n",
    "            (\n",
    "                node_feat,\n",
    "                node_opcode,\n",
    "                edge_index,\n",
    "                node_config_feat,\n",
    "                node_config_ids,\n",
    "                config_edge_index,\n",
    "            ) = (\n",
    "                node_feat.to(device),\n",
    "                node_opcode.to(device),\n",
    "                edge_index.to(device),\n",
    "                node_config_feat.to(device),\n",
    "                node_config_ids.to(device),\n",
    "                config_edge_index.to(device),\n",
    "            )\n",
    "            config_runtime = config_runtime.numpy()\n",
    "            c = config_runtime.shape[-1]\n",
    "            outs = []\n",
    "\n",
    "            for i in range(0, c, INFERENCE_CONFIGS_BATCH_SIZE):\n",
    "                end_i = min(i + INFERENCE_CONFIGS_BATCH_SIZE, c)\n",
    "                with autocast():\n",
    "                    out: torch.Tensor = model(\n",
    "                        node_feat,\n",
    "                        node_opcode,\n",
    "                        edge_index,\n",
    "                        node_config_feat[i:end_i],\n",
    "                        node_config_ids,\n",
    "                        config_edge_index,\n",
    "                    )\n",
    "                outs.append(out.detach().cpu())\n",
    "\n",
    "            outs = torch.concat(outs)\n",
    "            val_loss.append(criterion(outs, torch.from_numpy(config_runtime)).item())\n",
    "            \n",
    "            outs = outs.numpy()\n",
    "            kendalltau_scores.append(kendall(np.argsort(outs), np.argsort(config_runtime)))\n",
    "            opa_scores.append(opa(config_runtime[None], outs[None]))\n",
    "            top100_scores.append(topk_error(outs, config_runtime, top_k=100))\n",
    "            top500_scores.append(topk_error(outs, config_runtime, top_k=500))\n",
    "\n",
    "    val_loss_mean = np.mean(val_loss)\n",
    "    kendalltau_mean = np.mean(kendalltau_scores)\n",
    "    opa_mean = np.mean(opa_scores)\n",
    "    top100_mean = np.mean(top100_scores)\n",
    "    top500_mean = np.mean(top500_scores)\n",
    "    scheduler.step(kendalltau_mean)\n",
    "\n",
    "    if not DEBUG:\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"val/loss\": val_loss_mean,\n",
    "                \"val/kendalltau\": kendalltau_mean,\n",
    "                \"val/opa\": opa_mean,\n",
    "                \"val/top100_error\": top100_mean,\n",
    "                \"val/top500_error\": top500_mean,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch}, val/loss={val_loss:.4f}, \"\n",
    "        f\"kendall = {kendalltau_mean:.4f},\"\n",
    "        f\"opa = {opa_mean:.4f}, \"\n",
    "        f\"top500 = {top500_mean:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Update best scores and save the model if the mean score improves\n",
    "    if kendalltau_mean > best_score:\n",
    "        best_score = kendalltau_mean\n",
    "        print(f\"Best score updated: {best_score:.4f}\")\n",
    "        if not DEBUG:\n",
    "            filename = f\"{epoch}_{kendalltau_mean:.4f}.pth\"\n",
    "            path = os.path.join(wandb.run.dir, filename)\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                path,\n",
    "            )\n",
    "\n",
    "if not DEBUG:\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
