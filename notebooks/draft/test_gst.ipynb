{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gfos.data.constants import CONFIG_RUNTIME_MEAN_STD\n",
    "from gfos.metrics import LayoutMetrics\n",
    "\n",
    "from gfos.data.utils import load_layout\n",
    "\n",
    "source = \"nlp\"\n",
    "search = \"default\"\n",
    "\n",
    "data_root = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\"\n",
    "data_root = Path(data_root)\n",
    "\n",
    "xla_default = load_layout(data_root, compile_type=search, model_type=source)\n",
    "\n",
    "grad_clip = 1.0\n",
    "num_configs = 256\n",
    "epoch_infer = 400\n",
    "accum_iter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gfos.data.graph import get_config_graph\n",
    "\n",
    "\n",
    "class LayoutData(Data):\n",
    "    def __inc__(self, key: str, value: Any, *args, **kwargs) -> Any:\n",
    "        if key in (\"node_config_ids\", \"edge_index\"):\n",
    "            return self.num_nodes\n",
    "        elif key == \"config_edge_index\":\n",
    "            return self.num_config_nodes\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __cat_dim__(self, key: str, value: Any, *args, **kwargs) -> Any:\n",
    "        if \"index\" in key or \"node_config_feat\" == key:\n",
    "            return 1\n",
    "        elif (\n",
    "            \"node_opcode\" in key or \"node_config_ids\" in key or \"config_runtime\" in key\n",
    "        ):\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Normalizer:\n",
    "    node_feat_mask: torch.Tensor\n",
    "    node_feat_min: torch.Tensor\n",
    "    node_feat_max: torch.Tensor\n",
    "    node_config_feat_mask: torch.Tensor\n",
    "    node_config_feat_min: torch.Tensor\n",
    "    node_config_feat_max: torch.Tensor\n",
    "\n",
    "    def normalize_node_feat(self, node_feat: torch.Tensor) -> torch.Tensor:\n",
    "        assert node_feat.ndim == 2, \"node_feat must be 2D\"\n",
    "        node_feat = node_feat[:, self.node_feat_mask]\n",
    "\n",
    "        return (node_feat - self.node_feat_min) / (\n",
    "            self.node_feat_max - self.node_feat_min\n",
    "        )\n",
    "\n",
    "    def normalize_node_config_feat(\n",
    "        self, node_config_feat: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        assert node_config_feat.ndim == 3, \"node_config_feat must be 3D\"\n",
    "        node_config_feat = node_config_feat[:, :, self.node_config_feat_mask]\n",
    "        return (node_config_feat - self.node_config_feat_min) / (\n",
    "            self.node_config_feat_max - self.node_config_feat_min\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(\n",
    "        cls,\n",
    "        configs: dict,\n",
    "        source: Literal[\"xla\", \"nlp\"],\n",
    "        search: Literal[\"default\", \"random\"],\n",
    "    ) -> \"Normalizer\":\n",
    "        try:\n",
    "            data = configs[source][search]\n",
    "        except KeyError:\n",
    "            raise KeyError(\n",
    "                f\"Invalid source or search: source={source}, search={search}\"\n",
    "            )\n",
    "        else:\n",
    "            node_feat_mask = torch.tensor(data[\"node_feat_mask\"], dtype=torch.bool)\n",
    "            node_feat_min = torch.tensor(data[\"node_feat_min\"], dtype=torch.float)[\n",
    "                node_feat_mask\n",
    "            ]\n",
    "            node_feat_max = torch.tensor(data[\"node_feat_max\"], dtype=torch.float)[\n",
    "                node_feat_mask\n",
    "            ]\n",
    "            node_config_feat_mask = torch.tensor(\n",
    "                data[\"node_config_feat_mask\"], dtype=torch.bool\n",
    "            )\n",
    "            node_config_feat_min = torch.tensor(\n",
    "                data[\"node_config_feat_min\"], dtype=torch.float\n",
    "            )[node_config_feat_mask]\n",
    "            node_config_feat_max = torch.tensor(\n",
    "                data[\"node_config_feat_max\"], dtype=torch.float\n",
    "            )[node_config_feat_mask]\n",
    "\n",
    "            return Normalizer(\n",
    "                node_feat_mask=node_feat_mask,\n",
    "                node_feat_min=node_feat_min,\n",
    "                node_feat_max=node_feat_max,\n",
    "                node_config_feat_mask=node_config_feat_mask,\n",
    "                node_config_feat_min=node_config_feat_min,\n",
    "                node_config_feat_max=node_config_feat_max,\n",
    "            )\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path, source, search):\n",
    "        import json\n",
    "\n",
    "        json_data = json.load(open(path))\n",
    "        return Normalizer.from_dict(json_data, source, search)\n",
    "\n",
    "\n",
    "class LayoutDataset(Dataset):\n",
    "    \"\"\"Load all data in advance.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        files: list[str],\n",
    "        max_configs: int = -1,\n",
    "        num_configs: int = -1,\n",
    "        normalizer: Normalizer = None,\n",
    "        bins: np.array = None,\n",
    "        three_split_sampling: bool = True,\n",
    "        indices_dir: str = None,\n",
    "        runtime_mean: float = None,\n",
    "        runtime_std: float = None,\n",
    "        thres: int = 5000,\n",
    "    ):\n",
    "        self.max_configs = max_configs\n",
    "        self.num_configs = num_configs\n",
    "        self.files = files\n",
    "        self.normalizer = normalizer\n",
    "        self.thres = thres\n",
    "\n",
    "        if indices_dir is not None:\n",
    "            if not Path(indices_dir).exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Fold index dir <{indices_dir}> \" \"specified but does not exist\"\n",
    "                )\n",
    "            indices_dir = Path(indices_dir)\n",
    "            target_models = set([f.stem for f in indices_dir.glob(\"*.npy\")])\n",
    "            self.files = [f for f in files if Path(f).stem in target_models]\n",
    "        else:\n",
    "            self.files = files\n",
    "\n",
    "        self.data = []\n",
    "        pbar = tqdm(self.files, desc=\"Loading data\")\n",
    "        parts_cnt = 0\n",
    "\n",
    "        for file in pbar:\n",
    "            record = dict(np.load(file))\n",
    "            model_id = Path(file).stem\n",
    "            pbar.set_postfix_str(model_id)\n",
    "\n",
    "            record[\"model_id\"] = model_id\n",
    "            runtime = record[\"config_runtime\"]\n",
    "\n",
    "            if bins is not None:\n",
    "                cls_lables = np.digitize(runtime, bins)\n",
    "\n",
    "            if runtime_mean is None or runtime_std is None:\n",
    "                runtime = (runtime - runtime.mean()) / runtime.std()\n",
    "            else:\n",
    "                runtime = (runtime - runtime_mean) / runtime_std\n",
    "\n",
    "            if indices_dir is not None:\n",
    "                indices_file = Path(indices_dir) / f\"{model_id}.npy\"\n",
    "                if indices_file.exists():\n",
    "                    config_indices = np.load(indices_file)\n",
    "                    runtime_sampled = runtime[config_indices]\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"{indices_file} does not exist\")\n",
    "            else:\n",
    "                if self.max_configs > 0:\n",
    "                    # sample `max_configs` with order\n",
    "                    # [good_configs, bad_configs, random_configs]\n",
    "                    if three_split_sampling:\n",
    "                        runtime_sampled, config_indices = sample_configs(\n",
    "                            runtime, max_configs\n",
    "                        )\n",
    "                    else:\n",
    "                        config_indices = torch.randperm(len(runtime))[:max_configs]\n",
    "                        runtime_sampled = runtime[config_indices]\n",
    "                else:\n",
    "                    # use all configs\n",
    "                    runtime_sampled = runtime\n",
    "                    config_indices = torch.arange(len(runtime))\n",
    "\n",
    "            record[\"config_runtime\"] = runtime_sampled\n",
    "            record[\"node_config_feat\"] = record[\"node_config_feat\"][config_indices]\n",
    "            record[\"argsort_runtime\"] = np.argsort(runtime_sampled)\n",
    "\n",
    "            if bins is not None:\n",
    "                record[\"cls_label\"] = cls_lables[config_indices]\n",
    "\n",
    "            # create graph for configurable nodes\n",
    "            config_edge_index, edge_weight, paths = get_config_graph(\n",
    "                record[\"edge_index\"],\n",
    "                record[\"node_config_ids\"],\n",
    "            )\n",
    "            record[\"config_edge_weight\"] = torch.tensor(edge_weight, dtype=torch.float)\n",
    "            record[\"config_edge_path\"] = paths\n",
    "\n",
    "            config_edge_index = torch.tensor(\n",
    "                config_edge_index.T,\n",
    "                dtype=torch.long,\n",
    "            )\n",
    "            record[\"config_edge_index\"] = config_edge_index\n",
    "\n",
    "            record[\"config_runtime\"] = torch.tensor(\n",
    "                record[\"config_runtime\"], dtype=torch.float\n",
    "            )\n",
    "            record[\"argsort_runtime\"] = torch.tensor(\n",
    "                record[\"argsort_runtime\"], dtype=torch.long\n",
    "            )\n",
    "            record[\"node_feat\"] = torch.tensor(record[\"node_feat\"], dtype=torch.float)\n",
    "            record[\"node_opcode\"] = torch.tensor(\n",
    "                record[\"node_opcode\"], dtype=torch.long\n",
    "            )\n",
    "            record[\"edge_index\"] = torch.tensor(\n",
    "                record[\"edge_index\"].T, dtype=torch.long\n",
    "            )\n",
    "            record[\"node_config_feat\"] = torch.tensor(\n",
    "                record[\"node_config_feat\"], dtype=torch.float\n",
    "            )\n",
    "            record[\"node_config_ids\"] = torch.tensor(\n",
    "                record[\"node_config_ids\"], dtype=torch.long\n",
    "            )\n",
    "\n",
    "            # GST\n",
    "            num_nodes = torch.tensor(record[\"node_feat\"].shape[0])\n",
    "            num_parts = num_nodes // self.thres + 1\n",
    "            interval = num_nodes // num_parts\n",
    "            partptr = torch.arange(0, num_nodes, interval + 1)\n",
    "            if partptr[-1] != num_nodes:\n",
    "                partptr = torch.cat([partptr, torch.tensor([num_nodes])])\n",
    "\n",
    "            record[\"partptr\"] = partptr\n",
    "            record[\"num_nodes\"] = num_nodes\n",
    "            record[\"num_configs\"] = torch.tensor(len(record[\"config_runtime\"]))\n",
    "            record[\"partition_idx\"] = parts_cnt\n",
    "            parts_cnt += (num_parts * record[\"num_configs\"]).item()\n",
    "\n",
    "\n",
    "            if self.normalizer is not None:\n",
    "                record[\"node_feat\"] = self.normalizer.normalize_node_feat(\n",
    "                    record[\"node_feat\"]\n",
    "                )\n",
    "                record[\"node_config_feat\"] = self.normalizer.normalize_node_config_feat(\n",
    "                    record[\"node_config_feat\"]\n",
    "                )\n",
    "\n",
    "            if bins is not None:\n",
    "                record[\"cls_label\"] = torch.tensor(\n",
    "                    record[\"cls_label\"], dtype=torch.long\n",
    "                )\n",
    "\n",
    "            self.data.append(record)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx) -> dict[str, Any]:\n",
    "        record = self.data[idx]\n",
    "\n",
    "        config_runtime = record[\"config_runtime\"]\n",
    "        node_feat = record[\"node_feat\"]\n",
    "        node_opcode = record[\"node_opcode\"]\n",
    "        edge_index = record[\"edge_index\"]\n",
    "        node_config_feat = record[\"node_config_feat\"]\n",
    "        node_config_ids = record[\"node_config_ids\"]\n",
    "        argsort_runtime = record[\"argsort_runtime\"]\n",
    "        config_edge_index = record[\"config_edge_index\"]\n",
    "        num_nodes = record[\"num_nodes\"]\n",
    "        num_configs = record[\"num_configs\"]\n",
    "        partptr = record[\"partptr\"]\n",
    "        partition_idx = record[\"partition_idx\"]\n",
    "\n",
    "        c = len(config_runtime)\n",
    "\n",
    "        if self.num_configs > 0:\n",
    "            num_configs = min(self.num_configs, c)\n",
    "        elif self.max_configs > 0:\n",
    "            num_configs = min(self.max_configs, c)\n",
    "        else:\n",
    "            num_configs = c\n",
    "\n",
    "        # Sample\n",
    "        if self.max_configs > 0 or self.num_configs > 0:\n",
    "            # config_indices = torch.randperm(config_runtime.size(0))[\n",
    "            #     :num_configs\n",
    "            # ]\n",
    "            idx = torch.topk(\n",
    "                # Sample wrt GumbulSoftmax([NumConfs, NumConfs-1, ..., 1])\n",
    "                (c - torch.arange(c)) / c - torch.log(-torch.log(torch.rand(c))),\n",
    "                num_configs,\n",
    "            )[1]\n",
    "            config_indices = argsort_runtime[idx]\n",
    "        else:\n",
    "            config_indices = torch.arange(num_configs)\n",
    "        config_runtime = config_runtime[config_indices]\n",
    "\n",
    "        model_id = record[\"model_id\"]\n",
    "\n",
    "        node_config_feat = node_config_feat[config_indices]\n",
    "\n",
    "        sample = dict(\n",
    "            model_id=model_id,\n",
    "            node_feat=node_feat,\n",
    "            node_opcode=node_opcode,\n",
    "            edge_index=edge_index,\n",
    "            node_config_feat=node_config_feat,\n",
    "            node_config_ids=node_config_ids,\n",
    "            config_runtime=config_runtime,\n",
    "            config_edge_index=config_edge_index,\n",
    "            num_config_nodes=len(node_config_ids),\n",
    "            num_config_edges=len(config_edge_index[0]),\n",
    "            num_nodes=num_nodes,\n",
    "            num_configs=num_configs,\n",
    "            partptr=partptr,\n",
    "            config_indices=config_indices,\n",
    "            partition_idx=partition_idx,\n",
    "        )\n",
    "\n",
    "        if \"cls_label\" in record:\n",
    "            sample[\"cls_label\"] = record[\"cls_label\"][config_indices]\n",
    "\n",
    "        return LayoutData(**sample)\n",
    "\n",
    "\n",
    "def sample_configs(config_runtime: np.array, max_configs: int) -> (np.array, np.array):\n",
    "    \"\"\"Sample 1/3 max_configs of best configs and 1/3 of worst configs,\n",
    "    and the rest randomly. Return the sampled configs and indices.\n",
    "    \"\"\"\n",
    "    c = len(config_runtime)\n",
    "    max_configs = min(max_configs, c) if max_configs > 0 else c\n",
    "    third = max_configs // 3\n",
    "\n",
    "    sorted_indices = np.argsort(config_runtime)\n",
    "\n",
    "    keep_indices = np.concatenate(\n",
    "        [\n",
    "            sorted_indices[:third],  # Good configs.\n",
    "            sorted_indices[-third:],  # Bad configs.\n",
    "            np.random.choice(\n",
    "                sorted_indices[third:-third],\n",
    "                max_configs - 2 * third,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return config_runtime[keep_indices], keep_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = 16\n",
    "norm_path = \"../../data/normalizer.json\"\n",
    "\n",
    "runtime_mean = CONFIG_RUNTIME_MEAN_STD[source][search][\"mean\"]\n",
    "runtime_std = CONFIG_RUNTIME_MEAN_STD[source][search][\"std\"]\n",
    "\n",
    "trainset = LayoutDataset(\n",
    "    xla_default[\"train\"],\n",
    "    max_configs=10240,\n",
    "    num_configs=num_configs,\n",
    "    normalizer=Normalizer.from_json(norm_path, source=source, search=search),\n",
    "    runtime_mean=runtime_mean,\n",
    "    runtime_std=runtime_std,\n",
    ")\n",
    "\n",
    "valset = LayoutDataset(\n",
    "    xla_default[\"valid\"],\n",
    "    normalizer=Normalizer.from_json(norm_path, source=source, search=search),\n",
    "    runtime_mean=runtime_mean,\n",
    "    runtime_std=runtime_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import Batch\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_adj(batch):\n",
    "    batch_list = batch.to_data_list()\n",
    "    processed_batch_list = []\n",
    "\n",
    "    for g in batch_list:\n",
    "        g.adj = SparseTensor(\n",
    "            row=g.edge_index[0],\n",
    "            col=g.edge_index[1],\n",
    "            sparse_sizes=(g.num_nodes, g.num_nodes),\n",
    "        )\n",
    "\n",
    "        processed_batch_list.append(g)\n",
    "\n",
    "    return Batch.from_data_list(processed_batch_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class History(torch.nn.Module):\n",
    "    r\"\"\"A historical embedding storage module.\"\"\"\n",
    "\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        pin_memory = device is None or str(device) == \"cpu\"\n",
    "        self.emb = torch.empty(\n",
    "            num_embeddings,\n",
    "            embedding_dim,\n",
    "            device=device,\n",
    "            pin_memory=pin_memory,\n",
    "            requires_grad=False,\n",
    "        )\n",
    "\n",
    "        self._device = torch.device(\"cpu\")\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.emb.fill_(0)\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        # Set the `_device` of the module without transfering `self.emb`.\n",
    "        self._device = fn(torch.zeros(1)).device\n",
    "        return self\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def pull(self, n_id: Optional[Tensor] = None) -> Tensor:\n",
    "        out = self.emb\n",
    "        if n_id is not None:\n",
    "            assert n_id.device == self.emb.device\n",
    "            out = out.index_select(0, n_id)\n",
    "        return out.to(device=self._device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def push(\n",
    "        self,\n",
    "        x,\n",
    "        n_id: Optional[Tensor] = None,\n",
    "        offset: Optional[Tensor] = None,\n",
    "        count: Optional[Tensor] = None,\n",
    "    ):\n",
    "        if n_id is None and x.size(0) != self.num_embeddings:\n",
    "            raise ValueError\n",
    "\n",
    "        elif n_id is None and x.size(0) == self.num_embeddings:\n",
    "            self.emb.copy_(x)\n",
    "\n",
    "        elif offset is None or count is None:\n",
    "            assert n_id.device == self.emb.device\n",
    "            self.emb[n_id] = x.to(self.emb.device)\n",
    "\n",
    "        else:  # Push in chunks:\n",
    "            src_o = 0\n",
    "            x = x.to(self.emb.device)\n",
    "            for (\n",
    "                dst_o,\n",
    "                c,\n",
    "            ) in zip(offset.tolist(), count.tolist()):\n",
    "                self.emb[dst_o : dst_o + c] = x[src_o : src_o + c]\n",
    "                src_o += c\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}({self.num_embeddings}, \"\n",
    "            f\"{self.embedding_dim}, emb_device={self.emb.device}, \"\n",
    "            f\"device={self._device})\"\n",
    "        )\n",
    "\n",
    "\n",
    "emb_table = History(500000000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfos.model.gnn as gfos_gnn\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(gfos_gnn)\n",
    "\n",
    "model = gfos_gnn.LayoutModel(\n",
    "    node_feat_dim=112,\n",
    "    node_config_dim=14,\n",
    "    config_neighbor_layer=\"GATConv\",\n",
    "    dropout=0.2,\n",
    "    num_config_neighbor_layers=2,\n",
    "    # config_neighbor_dropout_between_layers=0.2,\n",
    "    # config_dropout_between_layers=0.2,\n",
    "    head_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gfos.loss import BatchMultiElementRankLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6, betas=(0.85, 0.9))\n",
    "criterion = BatchMultiElementRankLoss(0.5, 50)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10000, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"gfos\", entity=\"edenn0\", name=f\"{source}_{search}_gst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10000):\n",
    "    loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=NUM_BATCHES,\n",
    "        shuffle=True,\n",
    "        follow_batch=[\"node_config_feat\", \"node_feat\"],\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(enumerate(loader), leave=False, desc=f\"Epoch: {epoch}\")\n",
    "    for iter, batch in pbar:\n",
    "        batch = get_adj(batch)\n",
    "        true = batch.config_runtime\n",
    "\n",
    "        batch_list = batch.to_data_list()\n",
    "        batch_train_list = []\n",
    "        batch_other = []\n",
    "        batch_num_parts = []\n",
    "        segments_to_train = []\n",
    "        skipped_batch = []\n",
    "        for i in range(len(batch_list)):\n",
    "            num_parts = len(batch_list[i].partptr) - 1\n",
    "\n",
    "            segment_to_train = np.random.randint(num_parts)\n",
    "\n",
    "            batch_other_ = []\n",
    "            add_target = False\n",
    "            for j in range(num_parts):\n",
    "                start = int(batch_list[i].partptr.cpu().numpy()[j])\n",
    "                length = int(batch_list[i].partptr.cpu().numpy()[j + 1]) - start\n",
    "\n",
    "                # filter out nodes that are not in the current partition\n",
    "                cidx = torch.where(\n",
    "                    (batch_list[i].node_config_ids >= start)\n",
    "                    & (batch_list[i].node_config_ids < start + length)\n",
    "                )[0]\n",
    "                if len(cidx) == 0:\n",
    "                    if j == segment_to_train:\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "                N, E, NC, EC = (\n",
    "                    batch_list[i].num_nodes,\n",
    "                    batch_list[i].num_edges,\n",
    "                    batch_list[i].num_config_nodes,\n",
    "                    batch_list[i].num_config_edges,\n",
    "                )\n",
    "\n",
    "                data = copy.copy(batch_list[i])\n",
    "                del data.num_nodes\n",
    "\n",
    "                # select the subgraph\n",
    "                adj, data.adj = data.adj, None\n",
    "                adj = adj.narrow(0, start, length).narrow(1, start, length)\n",
    "\n",
    "                # select the sub config graph\n",
    "                data.node_config_ids = data.node_config_ids[cidx] - start\n",
    "                data.node_config_feat = data.node_config_feat.index_select(1, cidx)\n",
    "\n",
    "                ei = data.config_edge_index\n",
    "                mask = torch.isin(ei, cidx).all(dim=0)\n",
    "                filtered_edge_index = ei[:, mask]\n",
    "\n",
    "                new_indices = torch.zeros(data.num_config_nodes, dtype=torch.long) - 1\n",
    "                new_indices[cidx] = torch.arange(cidx.size(0))\n",
    "\n",
    "                data.config_edge_index = new_indices[\n",
    "                    filtered_edge_index\n",
    "                ]  # map to new indices\n",
    "\n",
    "                for key, item in data:\n",
    "                    if (\n",
    "                        isinstance(item, torch.Tensor) and item.size(0) == N\n",
    "                    ):  # node_feat, node_opcode\n",
    "                        data[key] = item.narrow(0, start, length)\n",
    "                    else:\n",
    "                        data[key] = item\n",
    "\n",
    "                row, col, _ = adj.coo()\n",
    "                data.edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "                if j == segment_to_train:\n",
    "                    batch_train_list.append(\n",
    "                        LayoutData(\n",
    "                            node_feat=data.node_feat,\n",
    "                            node_opcode=data.node_opcode,\n",
    "                            edge_index=data.edge_index,\n",
    "                            node_config_feat=data.node_config_feat,\n",
    "                            node_config_ids=data.node_config_ids,\n",
    "                            config_runtime=data.config_runtime,\n",
    "                            config_edge_index=data.config_edge_index,\n",
    "                            num_config_nodes=len(data.node_config_ids),\n",
    "                            num_nodes=len(data.node_feat),\n",
    "                            model_id=data.model_id,\n",
    "                        )\n",
    "                    )\n",
    "                    add_target = True\n",
    "                else:\n",
    "                    batch_other_.append(\n",
    "                        emb_table.pull(\n",
    "                            batch_list[i].partition_idx.cpu()\n",
    "                            + data.config_indices * num_parts\n",
    "                            + j\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            if len(batch_other_) > 0 and add_target:\n",
    "                batch_other_ = torch.mean(torch.stack(batch_other_, dim=0), dim=0)\n",
    "                batch_other.append(batch_other_)\n",
    "                batch_num_parts.extend([num_parts] * num_configs)\n",
    "                segments_to_train.append(segment_to_train)\n",
    "            elif add_target:  # only training segment contains configurable nodes\n",
    "                batch_other.append(\n",
    "                    torch.zeros_like(batch_train_list[-1].config_runtime).unsqueeze(1)\n",
    "                )\n",
    "                batch_num_parts.extend([num_parts] * num_configs)\n",
    "                segments_to_train.append(segment_to_train)\n",
    "            else:\n",
    "                skipped_batch.append(i)\n",
    "\n",
    "        if len(batch_train_list) == 0:\n",
    "            continue\n",
    "\n",
    "        batch_seg = Batch.from_data_list(\n",
    "            batch_train_list, follow_batch=[\"node_config_feat\", \"node_feat\"]\n",
    "        )\n",
    "\n",
    "        node_feat = batch_seg[\"node_feat\"]\n",
    "        node_opcode = batch_seg[\"node_opcode\"]\n",
    "        edge_index = batch_seg[\"edge_index\"]\n",
    "        node_config_feat = batch_seg[\"node_config_feat\"]\n",
    "        node_config_ids = batch_seg[\"node_config_ids\"]\n",
    "        config_runtime = batch_seg[\"config_runtime\"]\n",
    "        config_edge_index = batch_seg[\"config_edge_index\"]\n",
    "        node_config_feat_batch = batch_seg[\"node_config_feat_batch\"]\n",
    "        batch_size = len(batch_seg.model_id)\n",
    "\n",
    "        (\n",
    "            node_feat,\n",
    "            node_opcode,\n",
    "            edge_index,\n",
    "            node_config_feat,\n",
    "            node_config_ids,\n",
    "            config_edge_index,\n",
    "            config_runtime,\n",
    "            node_config_feat_batch,\n",
    "        ) = (\n",
    "            node_feat.to(device),\n",
    "            node_opcode.to(device),\n",
    "            edge_index.to(device),\n",
    "            node_config_feat.to(device),\n",
    "            node_config_ids.to(device),\n",
    "            config_edge_index.to(device),\n",
    "            config_runtime.to(device),\n",
    "            node_config_feat_batch.to(device),\n",
    "        )\n",
    "\n",
    "        out = model(\n",
    "            node_feat,\n",
    "            node_opcode,\n",
    "            edge_index,\n",
    "            node_config_feat,\n",
    "            node_config_ids,\n",
    "            config_edge_index,\n",
    "            node_config_feat_batch,\n",
    "            batch_size,\n",
    "        )\n",
    "\n",
    "        out = out.reshape(num_configs, -1).T.contiguous().reshape(-1, 1)\n",
    "\n",
    "        binomial = torch.distributions.binomial.Binomial(probs=0.5)\n",
    "        if len(batch_other) > 0:\n",
    "            batch_other = torch.cat([b.to(device) for b in batch_other], dim=0)\n",
    "            mask = binomial.sample((batch_other.shape[0], 1)).to(device)\n",
    "            batch_other = batch_other.to(device)\n",
    "            batch_other_embed = batch_other * mask\n",
    "\n",
    "            batch_num_parts = torch.Tensor(batch_num_parts).to(device)\n",
    "            batch_num_parts = batch_num_parts.view(-1, 1)\n",
    "            multiplier_num = (batch_num_parts - 1) / 2 + 1\n",
    "            pred = out * multiplier_num + batch_other_embed\n",
    "        else:\n",
    "            pred = out\n",
    "\n",
    "        # pred = pred.reshape(-1, num_sample_config)\n",
    "        out = out.reshape(-1, num_configs)\n",
    "        config_runtime = config_runtime.reshape(-1, num_configs)\n",
    "\n",
    "        loss = criterion(out, config_runtime)\n",
    "        loss.backward()\n",
    "        pbar.set_postfix_str(f\"loss={loss.item():.4f}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward\n",
    "        if ((iter + 1) % accum_iter == 0) or (iter + 1 == len(trainset)):\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            run.log(\n",
    "                {\n",
    "                    \"train/loss\": loss.item(),\n",
    "                    \"train/lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        used_batch = [\n",
    "            batch_list[i] for i in range(len(batch_list)) if i not in skipped_batch\n",
    "        ]\n",
    "        for i in range(out.shape[0]):\n",
    "            config_idx = used_batch[i].config_indices\n",
    "            push_idx = (\n",
    "                batch_list[i].partition_idx.cpu()\n",
    "                + config_idx * (len(batch_list[i].partptr) - 1)\n",
    "                + segments_to_train[i]\n",
    "            )\n",
    "            emb_table.push(out[i].unsqueeze(1).cpu(), push_idx)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % epoch_infer != 0:\n",
    "        continue\n",
    "\n",
    "    model.eval()\n",
    "    metrics = LayoutMetrics()\n",
    "    val_outs = {}  # save the output for each model\n",
    "\n",
    "    for record in tqdm(\n",
    "        valset,\n",
    "        desc=f\"Valid epoch: {epoch}\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        config_runtime: torch.Tensor = record[\"config_runtime\"]\n",
    "        with torch.no_grad():\n",
    "            node_feat = record[\"node_feat\"]\n",
    "            node_opcode = record[\"node_opcode\"]\n",
    "            edge_index = record[\"edge_index\"]\n",
    "            node_config_feat = record[\"node_config_feat\"]\n",
    "            node_config_ids = record[\"node_config_ids\"]\n",
    "            config_runtime = record[\"config_runtime\"]\n",
    "            config_edge_index = record[\"config_edge_index\"]\n",
    "\n",
    "            (\n",
    "                node_feat,\n",
    "                node_opcode,\n",
    "                edge_index,\n",
    "                node_config_feat,\n",
    "                node_config_ids,\n",
    "                config_edge_index,\n",
    "            ) = (\n",
    "                node_feat.to(device),\n",
    "                node_opcode.to(device),\n",
    "                edge_index.to(device),\n",
    "                node_config_feat.to(device),\n",
    "                node_config_ids.to(device),\n",
    "                config_edge_index.to(device),\n",
    "            )\n",
    "\n",
    "            c = len(config_runtime)\n",
    "            outs = []\n",
    "\n",
    "            for i in range(0, c, 30):\n",
    "                end_i = min(i + 30, c)\n",
    "                out: torch.Tensor = model(\n",
    "                    node_feat,\n",
    "                    node_opcode,\n",
    "                    edge_index,\n",
    "                    node_config_feat[i:end_i],\n",
    "                    node_config_ids,\n",
    "                    config_edge_index,\n",
    "                )\n",
    "                outs.append(out.detach().cpu())\n",
    "            outs = torch.concat(outs)\n",
    "\n",
    "        metrics.add(\n",
    "            record[\"model_id\"],\n",
    "            outs.numpy(),\n",
    "            config_runtime.numpy(),\n",
    "        )\n",
    "\n",
    "        val_outs[record[\"model_id\"]] = outs.numpy()\n",
    "\n",
    "    prefix = \"val/\"\n",
    "    scores = metrics.compute_scores(prefix=prefix)\n",
    "\n",
    "    run.log(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 5)\n",
    "edge_index = torch.cat([torch.arange(0, 99).unsqueeze(0), torch.arange(1, 100).unsqueeze(0)], dim=0)\n",
    "node_config_ids = torch.arange(30, 40)\n",
    "node_config_feat = torch.randn(node_config_ids.size(0), 5)\n",
    "node_config_feat = node_config_feat.repeat(3, 1, 1)\n",
    "config_edge_index = torch.cat([torch.arange(0, 9).unsqueeze(0), torch.arange(1, 10).unsqueeze(0)], dim=0)\n",
    "\n",
    "x = LayoutData(\n",
    "    node_feat=x,\n",
    "    node_opcode=None,\n",
    "    edge_index=edge_index,\n",
    "    node_config_feat=node_config_feat,\n",
    "    node_config_ids=node_config_ids,\n",
    "    config_runtime=None,\n",
    "    config_edge_index=config_edge_index,\n",
    "    num_config_nodes=len(node_config_ids),\n",
    "    num_nodes=len(x),\n",
    "    model_id=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 35\n",
    "length = 10\n",
    "\n",
    "# filter out nodes that are not in the current partition\n",
    "cidx = torch.where(\n",
    "    (x.node_config_ids >= start)\n",
    "    & (x.node_config_ids < start + length)\n",
    ")[0]\n",
    "# if len(cidx) == 0:\n",
    "#     if j == segment_to_train:\n",
    "#         break\n",
    "#     continue\n",
    "\n",
    "N, E, NC = (\n",
    "    x.num_nodes,\n",
    "    x.num_edges,\n",
    "    x.num_config_nodes,\n",
    ")\n",
    "\n",
    "data = copy.copy(x)\n",
    "data.adj = SparseTensor(\n",
    "    row=data.edge_index[0],\n",
    "    col=data.edge_index[1],\n",
    "    sparse_sizes=(data.num_nodes, data.num_nodes),\n",
    ")\n",
    "del data.num_nodes\n",
    "\n",
    "# select the subgraph\n",
    "adj, data.adj = data.adj, None\n",
    "adj = adj.narrow(0, start, length).narrow(1, start, length)\n",
    "\n",
    "# select the sub config graph\n",
    "data.node_config_ids = data.node_config_ids[cidx] - start\n",
    "data.node_config_feat = data.node_config_feat.index_select(1, cidx)\n",
    "\n",
    "ei = data.config_edge_index\n",
    "mask = torch.isin(ei, cidx).all(dim=0)\n",
    "filtered_edge_index = ei[:, mask]\n",
    "\n",
    "new_indices = torch.zeros(data.num_config_nodes, dtype=torch.long) - 1\n",
    "new_indices[cidx] = torch.arange(cidx.size(0))\n",
    "\n",
    "data.config_edge_index = new_indices[filtered_edge_index]  # map to new indices\n",
    "\n",
    "for key, item in data:\n",
    "    if (\n",
    "        isinstance(item, torch.Tensor) and item.size(0) == N\n",
    "    ):  # node_feat, node_opcode\n",
    "        data[key] = item.narrow(0, start, length)\n",
    "    else:\n",
    "        data[key] = item\n",
    "\n",
    "row, col, _ = adj.coo()\n",
    "data.edge_index = torch.stack([row, col], dim=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
