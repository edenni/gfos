{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gfos.data.utils import load_layout\n",
    "from gfos.data.constants import mask_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYOUT_DIR = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\"\n",
    "sources = (\"xla\", \"nlp\")\n",
    "searchs = (\"default\", \"random\")\n",
    "features = (\"node_feat\", \"node_config_feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(LAYOUT_DIR, sources[0], searchs[0])\n",
    "files: dict = load_layout(LAYOUT_DIR, compile_type=\"random\", model_type=\"xla\")\n",
    "all_files = reduce(lambda x, y: x + y, files.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xla default node_feat finished\n",
      "xla default node_config_feat finished\n",
      "xla random node_feat finished\n",
      "xla random node_config_feat finished\n",
      "nlp default node_feat finished\n",
      "nlp default node_config_feat finished\n",
      "nlp random node_feat finished\n",
      "nlp random node_config_feat finished\n"
     ]
    }
   ],
   "source": [
    "normalizer = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for source in sources:\n",
    "    for search in searchs:\n",
    "        for feature in features:\n",
    "            if feature == \"node_feat\":\n",
    "                feats = [np.load(file)[feature] for file in all_files]\n",
    "                feats = np.concatenate(feats, axis=0)\n",
    "            elif feature == \"node_config_feat\":\n",
    "                # To reduce the memory usage, pre-allocate the memory\n",
    "                num_configs = [np.load(file)[feature].size // 18 for file in all_files]\n",
    "                num_all_configs = sum(num_configs)\n",
    "                num_cumsum_configs = np.cumsum(num_configs)\n",
    "                feats = np.zeros((num_all_configs, 18), dtype=np.float32)\n",
    "                for i, file in enumerate(all_files):\n",
    "                    start = 0 if i == 0 else num_cumsum_configs[i - 1]\n",
    "                    end = num_cumsum_configs[i]\n",
    "                    feats[start:end] = np.load(file)[\"node_config_feat\"].reshape(-1, 18)\n",
    "\n",
    "            node_min = np.min(feats, axis=0)\n",
    "            node_max = np.max(feats, axis=0)\n",
    "            mask = node_max != node_min\n",
    "            \n",
    "            normalizer[source][search].update({\n",
    "                f\"{feature}_mask\": mask.tolist(),\n",
    "                f\"{feature}_min\": node_min.tolist(),\n",
    "                f\"{feature}_max\": node_max.tolist(),\n",
    "            })\n",
    "            \n",
    "            del feats\n",
    "            \n",
    "            print(f\"{source} {search} {feature} finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(normalizer, open(\"../../data/normalizer.json\", \"w\"), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
