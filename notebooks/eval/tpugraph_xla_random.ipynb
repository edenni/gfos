{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from tpu_graphs.baselines.layout.data import get_npz_split, get_npz_dataset\n",
    "from tpu_graphs.baselines.layout.models import ResModel\n",
    "from gfos.data.utils import load_layout\n",
    "from gfos.metrics import metric_for_layout_collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\\xla\\random\"\n",
    "num_configs = 16\n",
    "max_configs = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset cache file:  ../../.cache\\183fdb5b63be0acd26e349c711cd2092-cache.npz\n",
      "loaded from ../../.cache\\183fdb5b63be0acd26e349c711cd2092-cache.npz\n",
      "dataset cache file:  ../../.cache\\49d2fed3dd1c2fa9431a8f3dbfcc8856-cache.npz\n",
      "loaded from ../../.cache\\49d2fed3dd1c2fa9431a8f3dbfcc8856-cache.npz\n",
      "dataset cache file:  ../../.cache\\4b5575854b617d0ada456693f00c61d7-cache.npz\n",
      "loaded from ../../.cache\\4b5575854b617d0ada456693f00c61d7-cache.npz\n"
     ]
    }
   ],
   "source": [
    "# valid_dataset = get_npz_split(\n",
    "#     os.path.join(data_root_dir, \"valid\"),\n",
    "#     min_configs=num_configs,\n",
    "#     max_configs=max_configs,\n",
    "#     cache_dir=\"../../.cache\",\n",
    "# )\n",
    "data_partition = get_npz_dataset(\n",
    "    data_root_dir,\n",
    "    min_train_configs=num_configs,\n",
    "    max_train_configs=max_configs,\n",
    "    cache_dir=\"../../.cache\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _graph_and_label(graph: tfgnn.GraphTensor):\n",
    "    # Return runtimes divded over large number: only ranking is required. The\n",
    "    # runtimes are in the 100K range\n",
    "    label = tf.cast(graph.node_sets[\"g\"][\"runtimes\"], tf.float32) / 1e7\n",
    "    return graph, label\n",
    "\n",
    "valid_ds = (\n",
    "    data_partition.validation.get_graph_tensors_dataset(num_configs)\n",
    "    .batch(batch_size, drop_remainder=False)\n",
    "    .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "    .map(_graph_and_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResModel(16, 119)\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_801628c441d4b633a0fe36b72248f8e5/\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_5260f25ba9d0eae9c5e563a16848fd08\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "model.forward(subconfigs_graph, num_configs=100, backprop=False);\n",
    "\n",
    "for v, lv in zip(model.variables, loaded.variables):\n",
    "    v.assign(lv.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 7/7 [22:45<00:00, 195.04s/it]\n"
     ]
    }
   ],
   "source": [
    "_INFERENCE_CONFIGS_BATCH_SIZE = 100\n",
    "\n",
    "test_rankings = []\n",
    "\n",
    "assert data_partition.validation.graph_id is not None\n",
    "\n",
    "for graph in tqdm.tqdm(\n",
    "    data_partition.validation.iter_graph_tensors(),\n",
    "    total=data_partition.validation.graph_id.shape[-1],\n",
    "    desc=\"Inference\",\n",
    "):\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=(end_i - i), backprop=False\n",
    "        )\n",
    "        all_scores.append(h[0])\n",
    "\n",
    "    all_scores = tf.concat(all_scores, axis=0)\n",
    "    graph_id = graph.node_sets[\"g\"][\"graph_id\"][0].numpy().decode()\n",
    "    sorted_indices = (\n",
    "        tf.strings.join(tf.strings.as_string(tf.argsort(all_scores)), \";\")\n",
    "        .numpy()\n",
    "        .decode()\n",
    "    )\n",
    "    test_rankings.append((graph_id, sorted_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYOUT_DIR = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\"\n",
    "layouts = load_layout(LAYOUT_DIR, model_type=\"xla\", compile_type=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_dict = dict(test_rankings)\n",
    "scores = []\n",
    "for file in layouts[\"valid\"]:\n",
    "    filename = os.path.basename(file)[:-4]\n",
    "    idx = pred_dict[filename].split(\";\")\n",
    "    idx = [int(i) for i in idx]\n",
    "    \n",
    "    runtime = np.load(file)[\"config_runtime\"]\n",
    "    pred = runtime[idx]\n",
    "    gt = runtime[np.argsort(runtime)]\n",
    "    \n",
    "    score = metric_for_layout_collections(pred, gt[:len(pred)])\n",
    "    scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00933916146226321"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
