{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from tpu_graphs.baselines.layout.data import get_npz_split, get_npz_dataset\n",
    "from tpu_graphs.baselines.layout.models import ResModel\n",
    "from gfos.data.utils import load_layout\n",
    "from gfos.metrics import kendall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\\xla\\default\"\n",
    "num_configs = 16\n",
    "max_configs = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:30<00:00,  2.00it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.94it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.95it/s]\n"
     ]
    }
   ],
   "source": [
    "partition = get_npz_dataset(\n",
    "    data_root_dir,\n",
    "    min_train_configs=-1,\n",
    "    max_train_configs=max_configs,\n",
    "    cache_dir=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _graph_and_label(graph: tfgnn.GraphTensor):\n",
    "    # Return runtimes divded over large number: only ranking is required. The\n",
    "    # runtimes are in the 100K range\n",
    "    label = tf.cast(graph.node_sets[\"g\"][\"runtimes\"], tf.float32) / 1e7\n",
    "    return graph, label\n",
    "\n",
    "valid_ds = (\n",
    "    partition.validation.get_graph_tensors_dataset(num_configs)\n",
    "    .batch(batch_size, drop_remainder=False)\n",
    "    .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "    .map(_graph_and_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       " 'train_loss': [30.041467666625977,\n",
       "  29.264562606811523,\n",
       "  28.696121215820312,\n",
       "  28.339834213256836,\n",
       "  28.21565055847168,\n",
       "  27.840320587158203,\n",
       "  27.37835121154785,\n",
       "  26.948945999145508,\n",
       "  26.4381103515625,\n",
       "  25.360946655273438,\n",
       "  24.65704345703125,\n",
       "  23.751651763916016,\n",
       "  23.117752075195312,\n",
       "  22.623207092285156,\n",
       "  22.0583438873291,\n",
       "  21.676252365112305,\n",
       "  22.130577087402344,\n",
       "  21.463748931884766],\n",
       " 'train_opa': [0.602922797203064,\n",
       "  0.6148240566253662,\n",
       "  0.6387278437614441,\n",
       "  0.6591513156890869,\n",
       "  0.6567494869232178,\n",
       "  0.673766016960144,\n",
       "  0.6938405632972717,\n",
       "  0.7094371318817139,\n",
       "  0.7420185804367065,\n",
       "  0.7807303667068481,\n",
       "  0.7961590886116028,\n",
       "  0.8080283403396606,\n",
       "  0.813093900680542,\n",
       "  0.8177865743637085,\n",
       "  0.8253482580184937,\n",
       "  0.83106529712677,\n",
       "  0.825078547000885,\n",
       "  0.8349705934524536],\n",
       " 'val_loss': [30.23636817932129,\n",
       "  28.91695785522461,\n",
       "  29.183935165405273,\n",
       "  29.106632232666016,\n",
       "  28.099651336669922,\n",
       "  28.104442596435547,\n",
       "  28.09746742248535,\n",
       "  27.10452651977539,\n",
       "  26.045185089111328,\n",
       "  25.29905128479004,\n",
       "  23.795162200927734,\n",
       "  24.03879165649414,\n",
       "  22.26482582092285,\n",
       "  22.504074096679688,\n",
       "  21.654321670532227,\n",
       "  22.300317764282227,\n",
       "  21.718067169189453,\n",
       "  21.592918395996094],\n",
       " 'val_opa': [0.5741666555404663,\n",
       "  0.6641666889190674,\n",
       "  0.6116666793823242,\n",
       "  0.6316666603088379,\n",
       "  0.6795833110809326,\n",
       "  0.6670833230018616,\n",
       "  0.6954166889190674,\n",
       "  0.7215506434440613,\n",
       "  0.7962499856948853,\n",
       "  0.784166693687439,\n",
       "  0.8354166746139526,\n",
       "  0.8062499761581421,\n",
       "  0.8141666650772095,\n",
       "  0.8370833396911621,\n",
       "  0.8270833492279053,\n",
       "  0.8441666960716248,\n",
       "  0.847083330154419,\n",
       "  0.856249988079071]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "\n",
    "args = json.load(gzip.open(\"../../src/tpu_graphs/output/run_aaa7c9876d5bde19db56594f7334657c.jsonz\"))\n",
    "args[\"train_curve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResModel(16, 119)\n",
    "sample_graph, = partition.validation.get_graph_tensors_dataset(num_configs).take(1)  # Example graph to invoke `model.forward`.\n",
    "model.forward(sample_graph, num_configs, backprop=False)\n",
    "del sample_graph  # No longer need a toy example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xla random\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_801628c441d4b633a0fe36b72248f8e5/\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "# xla default\n",
    "loaded = tf.keras.models.load_model(\n",
    "    \"../../src/tpu_graphs/output/model_5260f25ba9d0eae9c5e563a16848fd08\",\n",
    "    custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    ")\n",
    "\n",
    "# model.forward(subconfigs_graph, num_configs=100, backprop=False)\n",
    "# # nlp default\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_aaa7c9876d5bde19db56594f7334657c\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "\n",
    "for v, lv in zip(model.variables, loaded.variables):\n",
    "    v.assign(lv.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 7/7 [23:47<00:00, 203.99s/it]\n"
     ]
    }
   ],
   "source": [
    "_INFERENCE_CONFIGS_BATCH_SIZE = 100\n",
    "\n",
    "test_rankings = []\n",
    "\n",
    "assert partition.validation.graph_id is not None\n",
    "\n",
    "for graph in tqdm.tqdm(\n",
    "    partition.validation.iter_graph_tensors(),\n",
    "    total=partition.validation.graph_id.shape[-1],\n",
    "    desc=\"Inference\",\n",
    "):\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=end_i-i, backprop=False\n",
    "        )\n",
    "        all_scores.append(h[0])\n",
    "\n",
    "    all_scores = tf.concat(all_scores, axis=0)\n",
    "    graph_id = graph.node_sets[\"g\"][\"graph_id\"][0].numpy().decode()\n",
    "    sorted_indices = (\n",
    "        tf.strings.join(tf.strings.as_string(tf.argsort(all_scores)), \";\")\n",
    "        .numpy()\n",
    "        .decode()\n",
    "    )\n",
    "    test_rankings.append((graph_id, sorted_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYOUT_DIR = r\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\"\n",
    "layouts = load_layout(LAYOUT_DIR, model_type=\"xla\", compile_type=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu\"):\n",
    "    opa_metric = tfr.keras.metrics.OPAMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gfos.metrics import topk_error\n",
    "\n",
    "pred_dict = dict(test_rankings)\n",
    "scores = []\n",
    "opas = []\n",
    "\n",
    "\n",
    "for file in layouts[\"valid\"]:\n",
    "    filename = os.path.basename(file)[:-4]\n",
    "    idx = pred_dict[filename].split(\";\")\n",
    "    pred = [int(i) for i in idx]\n",
    "    \n",
    "    runtime = np.load(file)[\"config_runtime\"]\n",
    "    gt = np.argsort(runtime)\n",
    "\n",
    "    score = topk_error(np.array(pred), gt[:len(pred)], top_k=100, index=True)\n",
    "    # opa = opa_metric(pred[None], gt[:len(pred)][None])\n",
    "    scores.append(score)\n",
    "    # opas.append(opa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
