{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from tpu_graphs.baselines.layout.data import get_npz_dataset\n",
    "from tpu_graphs.baselines.layout.models import ResModel\n",
    "from gfos.metrics import kendall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"xla\"\n",
    "SEARCH = \"random\"\n",
    "\n",
    "# nlp random  aaa7c9876d5bde19db56594f7334657c\n",
    "# xla random  801628c441d4b633a0fe36b72248f8e5\n",
    "# xla default 5260f25ba9d0eae9c5e563a16848fd08\n",
    "\n",
    "RUN_ID = \"801628c441d4b633a0fe36b72248f8e5\"\n",
    "data_root_dir = rf\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\\{SOURCE}\\{SEARCH}\"\n",
    "MODEL_DIR = f\"../../src/tpu_graphs/output/model_{RUN_ID}\"\n",
    "RUN_FILE = f\"../../src/tpu_graphs/output/run_{RUN_ID}.jsonz\"\n",
    "_INFERENCE_CONFIGS_BATCH_SIZE = 100\n",
    "\n",
    "num_configs = 16\n",
    "max_configs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'xla',\n",
       " 'search': 'random',\n",
       " 'epochs': 50,\n",
       " 'batch_size': 4,\n",
       " 'configs': 16,\n",
       " 'max_configs': 1000,\n",
       " 'early_stop': 40,\n",
       " 'keep_nodes': 5000,\n",
       " 'learning_rate': 0.001,\n",
       " 'clip_norm': 0.01,\n",
       " 'out_dir': './output',\n",
       " 'results_csv': './output\\\\results_1695227430358_xla_random.csv',\n",
       " 'validate_batches': 10,\n",
       " 'run_id': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = json.load(gzip.open(RUN_FILE))\n",
    "args[\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:26<00:00,  2.60it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.12it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(140,), dtype=bool, numpy=\n",
      "array([ True, False, False,  True, False, False,  True,  True, False,\n",
      "       False,  True, False, False,  True, False,  True, False, False,\n",
      "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "        True,  True, False, False, False,  True,  True,  True,  True,\n",
      "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
      "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "        True, False,  True,  True,  True,  True,  True, False, False,\n",
      "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True, False])>, <tf.Tensor: shape=(1, 140), dtype=float32, numpy=\n",
      "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1., -1.,  0.,\n",
      "         0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)>, <tf.Tensor: shape=(1, 140), dtype=float32, numpy=\n",
      "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
      "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
      "        1.0000000e+00, 1.8432000e+08, 3.7273600e+05, 3.7273600e+05,\n",
      "        3.7273600e+05, 2.0480000e+03, 2.5600000e+02, 1.8432000e+08,\n",
      "        2.9491200e+09, 3.5030000e+03, 3.5000000e+01, 4.0000000e+00,\n",
      "        4.0000000e+00, 4.0000000e+00, 5.0000000e+00, 4.0000000e+00,\n",
      "        5.0000000e+00, 5.1200000e+02, 5.1200000e+02, 1.2800000e+02,\n",
      "        3.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0240000e+03,\n",
      "        2.0971520e+06, 4.0000000e+00, 4.0000000e+00, 3.0000000e+00,\n",
      "        2.0000000e+00, 1.0000000e+00, 0.0000000e+00, 8.0000000e+00,\n",
      "        1.6000000e+01, 7.9000000e+01, 1.2700000e+02, 4.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2700000e+02,\n",
      "        1.6000000e+01, 4.0000000e+00, 4.0000000e+00, 4.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0000000e+00,\n",
      "        1.8000000e+01, 4.0000000e+00, 4.0000000e+00, 2.0000000e+00,\n",
      "        1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 8.0000000e+00,\n",
      "        1.6000000e+01, 4.0000000e+00, 4.0000000e+00, 3.0000000e+00,\n",
      "        1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 8.0000000e+00,\n",
      "        1.6000000e+01, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.0000000e+00,\n",
      "        5.0000000e+00, 4.0000000e+00, 4.0000000e+00, 3.0000000e+00,\n",
      "        2.0000000e+00, 3.0000000e+00, 0.0000000e+00, 4.0000000e+00,\n",
      "        4.0000000e+00, 1.0000000e+00, 2.0000000e+00, 3.0000000e+00,\n",
      "        0.0000000e+00, 3.0000000e+00, 4.0000000e+00, 3.8400000e+03,\n",
      "        3.8400000e+03, 1.0240000e+03, 1.1964600e+05, 1.1964600e+05,\n",
      "        1.0240000e+03, 1.0000000e+00, 1.0000000e+00, 5.0000000e+00,\n",
      "        1.0000000e+00, 1.2375000e+04, 1.9660800e+05, 1.9661400e+05,\n",
      "        8.0530637e+08, 1.2000000e+01, 2.0480000e+03, 3.3784000e+04,\n",
      "        2.5887744e+07, 1.0000000e+00, 6.4000000e+01, 6.4000000e+01,\n",
      "        1.0000000e+00, 7.6800000e+02, 5.1100000e+02, 3.3784000e+04,\n",
      "        2.5887744e+07, 1.0000000e+00, 5.0000000e+00, 4.0000000e+00,\n",
      "        5.0000000e+00, 3.0000000e+00, 2.0000000e+00, 0.0000000e+00]],\n",
      "      dtype=float32)>)\n",
      "(<tf.Tensor: shape=(18,), dtype=bool, numpy=\n",
      "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True, False, False, False, False])>, <tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
      "array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1.]], dtype=float32)>, <tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
      "array([[ 5.,  5.,  5.,  5.,  5.,  4.,  5.,  5.,  5.,  5.,  5.,  4.,  4.,\n",
      "         4., -1., -1., -1., -1.]], dtype=float32)>)\n",
      "num_ops: 119\n"
     ]
    }
   ],
   "source": [
    "# Need to comment out _TOY_DATA in get_npz_split\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    # Load whole dataset to get `num_ops`\n",
    "    dataset = get_npz_dataset(\n",
    "        data_root_dir,\n",
    "        min_train_configs=-1,\n",
    "        max_train_configs=max_configs,\n",
    "        cache_dir=None,\n",
    "    )\n",
    "\n",
    "    num_ops = dataset.num_ops\n",
    "    print(f\"num_ops: {num_ops}\")\n",
    "    # del dataset\n",
    "\n",
    "    # Load whole valid data will raise error:\n",
    "    # Cannot create a tensor proto whose content is larger than 2GB.\n",
    "    # valid_split = get_npz_split(\n",
    "    #     data_root_dir + r\"\\valid\",\n",
    "    #     max_configs=1000,\n",
    "    #     cache_dir=None,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResModel(num_configs, num_ops)\n",
    "\n",
    "for graph in dataset.validation.iter_graph_tensors():\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "\n",
    "    for i in range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=end_i-i, backprop=False\n",
    "        )\n",
    "        break\n",
    "    break\n",
    "\n",
    "loaded = tf.keras.models.load_model(\n",
    "    MODEL_DIR,\n",
    "    custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    ")\n",
    "\n",
    "for v, lv in zip(model.trainable_variables, loaded.trainable_variables):\n",
    "    v.assign(lv.value())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xla random\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_801628c441d4b633a0fe36b72248f8e5/\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "# xla default\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_5260f25ba9d0eae9c5e563a16848fd08\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert_pretraining.4x4.fp16:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "num_files = dataset.validation.graph_id.shape[-1]\n",
    "for i, graph in enumerate(dataset.validation.iter_graph_tensors()):\n",
    "    graph_id = graph.node_sets[\"g\"][\"graph_id\"][0].numpy().decode()\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "    outs = []\n",
    "\n",
    "    for i in tqdm.tqdm(\n",
    "        range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE),\n",
    "        total=int(np.ceil(num_configs / _INFERENCE_CONFIGS_BATCH_SIZE)),\n",
    "        desc=f\"{i}/{num_files} {graph_id}\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=end_i-i, backprop=False\n",
    "        )\n",
    "        outs.append(h[0])\n",
    "\n",
    "    outs = tf.concat(outs, axis=0)\n",
    "    sorted_indices = np.argsort(outs.numpy().squeeze())\n",
    "    true_indices = np.argsort(graph.node_sets[\"g\"][\"runtimes\"].numpy().squeeze())\n",
    "\n",
    "    scores.append(kendall(true_indices, sorted_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036985776985776994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nlp random: 0.5120780780780779"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
