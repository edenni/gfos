{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from tpu_graphs.baselines.layout.data import get_npz_dataset\n",
    "from tpu_graphs.baselines.layout.models import ResModel\n",
    "from gfos.metrics import kendall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"xla\"\n",
    "SEARCH = \"random\"\n",
    "\n",
    "# nlp random  aaa7c9876d5bde19db56594f7334657c\n",
    "# xla random  801628c441d4b633a0fe36b72248f8e5\n",
    "# xla default 5260f25ba9d0eae9c5e563a16848fd08\n",
    "\n",
    "RUN_ID = \"f50342e14012adf9da4ad3c0b046f0a6\"\n",
    "data_root_dir = rf\"H:\\data\\gfos\\predict-ai-model-runtime\\npz_all\\npz\\layout\\{SOURCE}\\{SEARCH}\"\n",
    "MODEL_DIR = f\"../../src/tpu_graphs/output/model_{RUN_ID}\"\n",
    "RUN_FILE = f\"../../src/tpu_graphs/output/run_{RUN_ID}.jsonz\"\n",
    "_INFERENCE_CONFIGS_BATCH_SIZE = 50\n",
    "\n",
    "num_configs = 16\n",
    "max_configs = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = json.load(gzip.open(RUN_FILE))\n",
    "# print(args[\"args\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to comment out _TOY_DATA in get_npz_split\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    # Load whole dataset to get `num_ops`\n",
    "    dataset = get_npz_dataset(\n",
    "        data_root_dir,\n",
    "        min_train_configs=-1,\n",
    "        max_train_configs=max_configs,\n",
    "        cache_dir=None,\n",
    "    )\n",
    "\n",
    "    num_ops = dataset.num_ops\n",
    "    print(f\"num_ops: {num_ops}\")\n",
    "    # del dataset\n",
    "\n",
    "    # Load whole valid data will raise error:\n",
    "    # Cannot create a tensor proto whose content is larger than 2GB.\n",
    "    # valid_split = get_npz_split(\n",
    "    #     data_root_dir + r\"\\valid\",\n",
    "    #     max_configs=1000,\n",
    "    #     cache_dir=None,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResModel(num_configs, num_ops)\n",
    "\n",
    "for graph in dataset.validation.iter_graph_tensors():\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "\n",
    "    for i in range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=end_i-i, backprop=False\n",
    "        )\n",
    "        break\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.keras.models.load_model(\n",
    "    MODEL_DIR,\n",
    "    compile=False,\n",
    "    custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    ")\n",
    "\n",
    "for v, lv in zip(model.trainable_variables, loaded.trainable_variables):\n",
    "    v.assign(lv.value())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xla random\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_801628c441d4b633a0fe36b72248f8e5/\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n",
    "\n",
    "# xla default\n",
    "# loaded = tf.keras.models.load_model(\n",
    "#     \"../../src/tpu_graphs/output/model_5260f25ba9d0eae9c5e563a16848fd08\",\n",
    "#     custom_objects={\"opa_metric\": tfr.keras.metrics.OPAMetric},\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "num_files = dataset.validation.graph_id.shape[-1]\n",
    "for i, graph in enumerate(dataset.validation.iter_graph_tensors()):\n",
    "    graph_id = graph.node_sets[\"g\"][\"graph_id\"][0].numpy().decode()\n",
    "    num_configs = graph.node_sets[\"g\"][\"runtimes\"].shape[-1]\n",
    "    outs = []\n",
    "\n",
    "    for i in tqdm.tqdm(\n",
    "        range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE),\n",
    "        total=int(np.ceil(num_configs / _INFERENCE_CONFIGS_BATCH_SIZE)),\n",
    "        desc=f\"[{i+1}/{num_files}] {graph_id}\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets[\"g\"]\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                \"op\": graph.node_sets[\"op\"],\n",
    "                \"nconfig\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets[\"nconfig\"].sizes,\n",
    "                    features={\n",
    "                        \"feats\": graph.node_sets[\"nconfig\"][\"feats\"][\n",
    "                            :, i:end_i\n",
    "                        ],\n",
    "                    },\n",
    "                ),\n",
    "                \"g\": tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        \"graph_id\": node_set_g[\"graph_id\"],\n",
    "                        \"runtimes\": node_set_g[\"runtimes\"][:, i:end_i],\n",
    "                        \"kept_node_ratio\": node_set_g[\"kept_node_ratio\"],\n",
    "                    },\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "        h = model.forward(\n",
    "            subconfigs_graph, num_configs=end_i-i, backprop=False\n",
    "        )\n",
    "        outs.append(h[0])\n",
    "\n",
    "    outs = tf.concat(outs, axis=0)\n",
    "    sorted_indices = np.argsort(outs.numpy().squeeze())\n",
    "    true_indices = np.argsort(graph.node_sets[\"g\"][\"runtimes\"].numpy().squeeze())\n",
    "\n",
    "    scores.append(kendall(true_indices, sorted_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nlp random: 0.5120780780780779  [5260f25ba9d0eae9c5e563a16848fd08]\n",
    "- xla random: 0.10891880891880891 [f50342e14012adf9da4ad3c0b046f0a6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
